% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/kld_knn.R
\name{kld_knn}
\alias{kld_knn}
\title{KL Divergence estimated via KNN}
\usage{
kld_knn(
  x,
  y,
  automate = TRUE,
  k = NULL,
  eps = NULL,
  whiten = FALSE,
  type = 1,
  lambda = 0.5,
  n_mc = 1
)
}
\arguments{
\item{x}{an n by p matrix of samples from P}

\item{y}{an m by p matrix of samples from Q}

\item{automate}{logical; If TRUE, eps is set using the data-driven approach of Eq 26-29 (using k=1, by default).}

\item{k}{number of nearest neighbors to use.}

\item{eps}{neighborhood radius to use (only k or epsilon should be specified). Uses generalized estimator (Eq 17 and Eq 25).}

\item{whiten}{logical; Should x and y be whitened using Eq 32-33 first?}

\item{type}{See details}

\item{lambda}{parameter (between 0 and 1) for the Population Stability Index (ignored unless type = 4)}

\item{n_mc}{number of monte carlo samples used when type = 3 or 4}
}
\description{
Returns the KLD estimator of Wang et al. (2009). Useful in high dimensions. For univariate samples, use \code{kld()} instead.
}
\details{
Follows Wang et al. 2009.
}
\examples{
x <- matrix(rnorm(2*500), ncol=2)
x[,2] <- 0.6*x[,2] + rnorm(2*500, 0, 0.4)
y <- matrix(rnorm(2*450, 0, 0.9), ncol=2)

kld_knn(x, y, TRUE, k=3)
kld_knn(x, y, TRUE, k=3, type=2)
kld_knn(x, y, TRUE, k=3, whiten=TRUE, type=2)
kld_knn(x, y, FALSE, k=5)
kld_knn(x, y, FALSE, eps = 1.5)

}
