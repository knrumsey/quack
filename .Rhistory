<<<<<<< HEAD
gs4_oauth_app()
?gs4_oauth_app
?gs4_oauth_app
sheets_deauth()
gs4_deauth()
rsconnect::deployApp('../Pile_Manager')
rsconnect::setAccountInfo(name='knrumsey', token='D4C90AE28077214D2D52FCDF2B851F16', secret='jeup5+kkkkr4UPh4nsHVpykiS6JclkIzb4BRQlwc')
library(rsconnect)
rsconnect::deployApp("../Pile_Manager")
rsconnect::setAccountInfo(name='knrumsey',
token='D4C90AE28077214D2D52FCDF2B851F16',
secret='jeup5+kkkkr4UPh4nsHVpykiS6JclkIzb4BRQlwc')
library(rsconnect)
rsconnect::deployApp("../Pile_Manager")
library(rsconnect)
rsconnect::deployApp("../Pile_Manager")
library(rsconnect)
rsconnect::deployApp("../Pile_Manager")
runApp()
runApp()
?downloadButton
library(shinyjs)
toggleState
?toggleState
?observe
runApp()
runApp()
runApp()
?disable
runApp()
runApp()
?downloadButton
runApp()
?enable
runApp()
rsconnect::setAccountInfo(name='knrumsey',
token='D4C90AE28077214D2D52FCDF2B851F16',
secret='jeup5+kkkkr4UPh4nsHVpykiS6JclkIzb4BRQlwc')
library(rsconnect)
rsconnect::deployApp("../Pile_Manager")
runApp()
library(mvtnorm)
1 %in% NULL
#' @param verbose should information on status be printed
#' @param crit a subset of c("aic", "bic", "hqic") corresponding to Aikike's, Bayesian and Hanaan-Quinn information criteria.
#' @param ... additional parameters passed to get_constMP (if norm=TRUE)
#' @return a list with components corresponding to the fit using the number of components specified by `K`
#' @examples
#' x <- rnorm(10)
#' dMP(x, w1=5, w2=2)
#' X <- matrix(rnorm(10*30), nrow=30)
#' apply(X, 1, dMP, w1=5, w2=2)
#' @export
mvn_mix <- function(X, K=1:3, epsilon=1e-5, max_iter=2000, verbose=FALSE, crit=NULL){
out <- list()
for(k in k_comp){
N_comp <- k
# Initialize model
SX <- cov(X)
a_n <- function(n, kap=0.75) n^(-kap)
pi <- (tmp <- runif(N_comp))/sum(tmp)
mu <- sigma <- list()
for(j in 1:N_comp){
mu[[j]]    <- X[sample(nrow(X), 1),]
sigma[[j]] <- rWishart(1, df=ncol(X)+2, SX)[,,1]
}
n <- nrow(X)
p <- N_comp
d <- nrow(SX)
pi_ij <- matrix(NA, nrow=n, ncol=p)
iter <- 1
tol <- Inf
log_lik <- rep(NA, max_iter)
while(tol > epsilon & iter < max_iter){
#E-STEP
for(i in 1:n){
for(j in 1:p){
xi <- X[i,]
pi_ij[i,j] <- pi[j] * dmvnorm(as.numeric(xi), as.numeric(mu[[j]]), sigma[[j]])
}
}
for(i in 1:n){
pi_ij[i,] <- pi_ij[i,]/sum(pi_ij[i,])
}
# M-STEP
Sj <- list()
for(j in 1:p){
tmp <- matrix(0, nrow=d, ncol=d)
for(i in 1:n){
xi <- X[i,]
tmp <- tmp + pi_ij[i,j]*tcrossprod(xi - mu[[j]])
}
Sj[[j]] <- tmp
}
#Update component probabilities
pi <- apply(pi_ij, 2, mean)
#Update covariance matrices
for(j in 1:p){
sigma[[j]] <- (2*a_n(n)*SX + Sj[[j]])/(2*a_n(n) + n*pi[j])
}
#Update mean vectors
for(j in 1:p){
tmp <- 0
for(i in 1:n){
xi <- X[i,]
tmp <- tmp + pi_ij[i,j]*xi
}
mu[[j]] <- tmp/(n*pi[j])
}
#Compute log likelihood
log_lik[iter] <- 0
for(i in 1:n){
tmp <- 0
xi <- X[i,]
for(j in 1:p){
tmp <- tmp + pi[j]*dmvnorm(xi, mu[[j]], sigma[[j]])
}
log_lik[iter] <- log_lik[iter] + log(tmp)
}
if((iter %% 10) == 0){
if(verbose)
cat("K: ", k, "\nIteration: ", iter, "\ntol: ", tol, "\n\n")
}
if(iter > 1){
tol <- log_lik[iter] - log_lik[iter - 1]
}
iter <- iter + 1
}
log_lik <- log_lik[1:(iter - 1)]
out[[k]] <- list(log_lik = log_lik,
pi = pi,
mu = mu,
sigma = sigma)
}
if(!is.null(crit)){
Kmax <- length(out)
bic <- ll <- rep(NA, Kmax)
aic <- hqic <- rep(NA, Kmax)
k <- 1
bic[1] <- -2*sum(log(dmvnorm(X, apply(X, 2, mean), cov(X)))) +
(k-1 + 5*k + 5*(5+1)/2*k)*log(nrow(X))
aic[1] <- -2*sum(log(dmvnorm(X, apply(X, 2, mean), cov(X)))) +
(k-1 + 5*k + 5*(5+1)/2*k)*2
hqic[1] <- -2*sum(log(dmvnorm(X, apply(X, 2, mean), cov(X)))) +
(k-1 + 5*k + 5*(5+1)/2*k)*2*log(log(n))
ll[1] <- sum(log(dmvnorm(X, apply(X, 2, mean), cov(X))))
for(k in 2:Kmax){
tmp <- out[[k]]$log_lik
bic[k] <- -2*max(tmp) + (k-1 + 5*k + 5*(5+1)/2*k)*log(nrow(X))
aic[k] <- -2*max(tmp) + (k-1 + 5*k + 5*(5+1)/2*k)*2
hqic[k]<- -2*max(tmp) + (k-1 + 5*k + 5*(5+1)/2*k)*2*log(log(nrow(X)))
ll[k] <- max(tmp)
}
out2 <- list(fits=out)
if("aic" %in% crit){
out2$aic <- aic
}
if("bic" %in% crit){
out2$bic <- bic
}
if("hqic" %in% crit){
out2$hqic <- hqic
}
return(out2)
}
return(out)
}
X <- rmvtnorm(100, c(0, 0), matrix(c(1, 0.4, 0.4, 1), byrow=TRUE))
X <- rmvnorm(100, c(0, 0), matrix(c(1, 0.4, 0.4, 1), byrow=TRUE))
X <- rmvtnorm(100, c(0, 0), matrix(c(1, 0.4, 0.4, 1), byrow=TRUE, nrow=2))
X <- rmvnorm(100, c(0, 0), matrix(c(1, 0.4, 0.4, 1), byrow=TRUE, nrow=2))
X
rbind(X, X)
X <- rmvnorm(100, c(0, 0), matrix(c(1, 0.4, 0.4, 1), byrow=TRUE, nrow=2))
X <- rbind(X, rmvnorm(100, c(0.2, 0.1), matrix(c(1, -0.3, -0.3, 1), byrow=TRUE, nrow=2)))
dim(X)
mvn_mix(X, 2, crit=c("bic", "aic", "hqic"))
#' @param verbose should information on status be printed
#' @param crit a subset of c("aic", "bic", "hqic") corresponding to Aikike's, Bayesian and Hanaan-Quinn information criteria.
#' @param ... additional parameters passed to get_constMP (if norm=TRUE)
#' @return a list with components corresponding to the fit using the number of components specified by `K`
#' @examples
#' x <- rnorm(10)
#' dMP(x, w1=5, w2=2)
#' X <- matrix(rnorm(10*30), nrow=30)
#' apply(X, 1, dMP, w1=5, w2=2)
#' @export
mvn_mix <- function(X, K=1:3, epsilon=1e-5, max_iter=2000, verbose=FALSE, crit=NULL){
out <- list()
for(k in K){
N_comp <- k
# Initialize model
SX <- cov(X)
a_n <- function(n, kap=0.75) n^(-kap)
pi <- (tmp <- runif(N_comp))/sum(tmp)
mu <- sigma <- list()
for(j in 1:N_comp){
mu[[j]]    <- X[sample(nrow(X), 1),]
sigma[[j]] <- rWishart(1, df=ncol(X)+2, SX)[,,1]
}
n <- nrow(X)
p <- N_comp
d <- nrow(SX)
pi_ij <- matrix(NA, nrow=n, ncol=p)
iter <- 1
tol <- Inf
log_lik <- rep(NA, max_iter)
while(tol > epsilon & iter < max_iter){
#E-STEP
for(i in 1:n){
for(j in 1:p){
xi <- X[i,]
pi_ij[i,j] <- pi[j] * dmvnorm(as.numeric(xi), as.numeric(mu[[j]]), sigma[[j]])
}
}
for(i in 1:n){
pi_ij[i,] <- pi_ij[i,]/sum(pi_ij[i,])
}
# M-STEP
Sj <- list()
for(j in 1:p){
tmp <- matrix(0, nrow=d, ncol=d)
for(i in 1:n){
xi <- X[i,]
tmp <- tmp + pi_ij[i,j]*tcrossprod(xi - mu[[j]])
}
Sj[[j]] <- tmp
}
#Update component probabilities
pi <- apply(pi_ij, 2, mean)
#Update covariance matrices
for(j in 1:p){
sigma[[j]] <- (2*a_n(n)*SX + Sj[[j]])/(2*a_n(n) + n*pi[j])
}
#Update mean vectors
for(j in 1:p){
tmp <- 0
for(i in 1:n){
xi <- X[i,]
tmp <- tmp + pi_ij[i,j]*xi
}
mu[[j]] <- tmp/(n*pi[j])
}
#Compute log likelihood
log_lik[iter] <- 0
for(i in 1:n){
tmp <- 0
xi <- X[i,]
for(j in 1:p){
tmp <- tmp + pi[j]*dmvnorm(xi, mu[[j]], sigma[[j]])
}
log_lik[iter] <- log_lik[iter] + log(tmp)
}
if((iter %% 10) == 0){
if(verbose)
cat("K: ", k, "\nIteration: ", iter, "\ntol: ", tol, "\n\n")
}
if(iter > 1){
tol <- log_lik[iter] - log_lik[iter - 1]
}
iter <- iter + 1
}
log_lik <- log_lik[1:(iter - 1)]
out[[k]] <- list(log_lik = log_lik,
pi = pi,
mu = mu,
sigma = sigma)
}
if(!is.null(crit)){
Kmax <- length(out)
bic <- ll <- rep(NA, Kmax)
aic <- hqic <- rep(NA, Kmax)
k <- 1
bic[1] <- -2*sum(log(dmvnorm(X, apply(X, 2, mean), cov(X)))) +
(k-1 + 5*k + 5*(5+1)/2*k)*log(nrow(X))
aic[1] <- -2*sum(log(dmvnorm(X, apply(X, 2, mean), cov(X)))) +
(k-1 + 5*k + 5*(5+1)/2*k)*2
hqic[1] <- -2*sum(log(dmvnorm(X, apply(X, 2, mean), cov(X)))) +
(k-1 + 5*k + 5*(5+1)/2*k)*2*log(log(n))
ll[1] <- sum(log(dmvnorm(X, apply(X, 2, mean), cov(X))))
for(k in 2:Kmax){
tmp <- out[[k]]$log_lik
bic[k] <- -2*max(tmp) + (k-1 + 5*k + 5*(5+1)/2*k)*log(nrow(X))
aic[k] <- -2*max(tmp) + (k-1 + 5*k + 5*(5+1)/2*k)*2
hqic[k]<- -2*max(tmp) + (k-1 + 5*k + 5*(5+1)/2*k)*2*log(log(nrow(X)))
ll[k] <- max(tmp)
}
out2 <- list(fits=out)
if("aic" %in% crit){
out2$aic <- aic
}
if("bic" %in% crit){
out2$bic <- bic
}
if("hqic" %in% crit){
out2$hqic <- hqic
}
return(out2)
}
return(out)
}
mvn_mix(X, 2, crit=c("bic", "aic", "hqic"))
mvn_mix(X, 1:2, crit=c("bic", "aic", "hqic"), verbose=TRUE)
plot(X)
X <- rmvnorm(100, c(0, 0), matrix(c(1, 0.4, 0.4, 1), byrow=TRUE, nrow=2))
X <- rbind(X, rmvnorm(300, c(1, 1.5), matrix(c(1, -0.7, -0.7, 1), byrow=TRUE, nrow=2)))
foo <- mvn_mix(X, 1:2, crit=c("bic", "aic", "hqic"), verbose=TRUE)
foo
plot(K)
plot(X)
foo$fits[[1]]
foo$fits[[2]]
cov(X)
foo$fits[[1]]$sigma
#' @param verbose should information on status be printed
#' @param crit a subset of c("aic", "bic", "hqic") corresponding to Aikike's, Bayesian and Hanaan-Quinn information criteria.
#' @param ... additional parameters passed to get_constMP (if norm=TRUE)
#' @return a list with components corresponding to the fit using the number of components specified by `K`
#' @examples
#' x <- rnorm(10)
#' dMP(x, w1=5, w2=2)
#' X <- matrix(rnorm(10*30), nrow=30)
#' apply(X, 1, dMP, w1=5, w2=2)
#' @export
mvn_mix <- function(X, K=1:3, epsilon=1e-5, max_iter=2000, verbose=FALSE, crit=NULL){
out <- list()
for(k in K){
N_comp <- k
# Initialize model
SX <- cov(X)
a_n <- function(n, kap=0.75) n^(-kap)
pi <- (tmp <- runif(N_comp))/sum(tmp)
mu <- sigma <- list()
for(j in 1:N_comp){
mu[[j]]    <- X[sample(nrow(X), 1),]
sigma[[j]] <- rWishart(1, df=ncol(X)+2, SX)[,,1]
}
n <- nrow(X)
p <- N_comp
d <- nrow(SX)
pi_ij <- matrix(NA, nrow=n, ncol=p)
iter <- 1
tol <- Inf
log_lik <- rep(NA, max_iter)
while(tol > epsilon & iter < max_iter){
#E-STEP
for(i in 1:n){
for(j in 1:p){
xi <- X[i,]
pi_ij[i,j] <- pi[j] * dmvnorm(as.numeric(xi), as.numeric(mu[[j]]), sigma[[j]])
}
}
for(i in 1:n){
pi_ij[i,] <- pi_ij[i,]/sum(pi_ij[i,])
}
# M-STEP
Sj <- list()
for(j in 1:p){
tmp <- matrix(0, nrow=d, ncol=d)
for(i in 1:n){
xi <- X[i,]
tmp <- tmp + pi_ij[i,j]*tcrossprod(xi - mu[[j]])
}
Sj[[j]] <- tmp
}
#Update component probabilities
pi <- apply(pi_ij, 2, mean)
#Update covariance matrices
for(j in 1:p){
sigma[[j]] <- (2*a_n(n)*SX + Sj[[j]])/(2*a_n(n) + n*pi[j])
}
#Update mean vectors
for(j in 1:p){
tmp <- 0
for(i in 1:n){
xi <- X[i,]
tmp <- tmp + pi_ij[i,j]*xi
}
mu[[j]] <- tmp/(n*pi[j])
}
#Compute log likelihood
log_lik[iter] <- 0
for(i in 1:n){
tmp <- 0
xi <- X[i,]
for(j in 1:p){
tmp <- tmp + pi[j]*dmvnorm(xi, mu[[j]], sigma[[j]])
}
log_lik[iter] <- log_lik[iter] + log(tmp)
}
if((iter %% 10) == 0){
if(verbose)
cat("K: ", k, "\nIteration: ", iter, "\ntol: ", tol, "\n\n")
}
if(iter > 1){
tol <- log_lik[iter] - log_lik[iter - 1]
}
iter <- iter + 1
}
log_lik <- log_lik[1:(iter - 1)]
out[[k]] <- list(log_lik = log_lik,
pi = pi,
mu = mu,
sigma = sigma)
}
if(!is.null(crit)){
nvar <- ncol(X)
Kmax <- length(out)
bic <- ll <- rep(NA, Kmax)
aic <- hqic <- rep(NA, Kmax)
k <- 1
bic[1] <- -2*sum(log(dmvnorm(X, apply(X, 2, mean), cov(X)))) +
(k-1 + nvar*k + nvar*(nvar+1)/2*k)*log(nrow(X))
aic[1] <- -2*sum(log(dmvnorm(X, apply(X, 2, mean), cov(X)))) +
(k-1 + nvar*k + nvar*(nvar+1)/2*k)*2
hqic[1] <- -2*sum(log(dmvnorm(X, apply(X, 2, mean), cov(X)))) +
(k-1 + nvar*k + nvar*(nvar+1)/2*k)*2*log(log(n))
ll[1] <- sum(log(dmvnorm(X, apply(X, 2, mean), cov(X))))
for(k in 2:Kmax){
tmp <- out[[k]]$log_lik
bic[k] <- -2*max(tmp) + (k-1 + nvar*k + nvar*(nvar+1)/2*k)*log(nrow(X))
aic[k] <- -2*max(tmp) + (k-1 + nvar*k + nvar*(nvar+1)/2*k)*2
hqic[k]<- -2*max(tmp) + (k-1 + nvar*k + nvar*(nvar+1)/2*k)*2*log(log(nrow(X)))
ll[k] <- max(tmp)
}
out2 <- list(fits=out)
if("aic" %in% crit){
out2$aic <- aic
}
if("bic" %in% crit){
out2$bic <- bic
}
if("hqic" %in% crit){
out2$hqic <- hqic
}
out2$ll <- ll
return(out2)
}
return(out)
}
foo <- mvn_mix(X, 1:2, crit=c("bic", "aic", "hqic"), verbose=TRUE)
cov(X)
foo$fits$[[1]]$sigma
foo$fits[[1]]$sigma
foot$fits[[2]]$sigma
foo$fits[[2]]$sigma
foo$fits[[2]]$mu
foo$fits[[2]]$pi
foo$fits[[2]]$mu
document()
library(devtools)
library(roxygen2)
document()
document()
n1 <- 100
mu1 <- c(0, 0)
sigma1 <- matrix(c(1, 0.5, 0.5, 1), nrow=2, byrow=TRUE)
X1 <- mvtnorm::mvnorm(n1, mu1, sigma1)
X1 <- mvtnorm::rmvnorm(n1, mu1, sigma1)
n1 <- 100
mu1 <- c(0, 0)
sigma1 <- matrix(c(1, 0.5, 0.5, 1), nrow=2, byrow=TRUE)
X1 <- mvtnorm::rmvnorm(n1, mu1, sigma1)
n2 <- 200
mu2 <- c(1, 1.5)
sigma2 <- matrix(c(1, 0.5, 0.5, 1), nrow=2, byrow=TRUE)
X2 <- mvtnorm::rmvnorm(n2, mu2, sigma2)
X <- rbind(X1, X2)
plot(X)
n1 <- 100
mu1 <- c(0, 0)
sigma1 <- matrix(c(1, 0.5, 0.5, 1), nrow=2, byrow=TRUE)
X1 <- mvtnorm::rmvnorm(n1, mu1, sigma1)
n2 <- 200
mu2 <- c(1, 1.5)
sigma2 <- matrix(c(1, -0.7, -0.7, 1), nrow=2, byrow=TRUE)
X2 <- mvtnorm::rmvnorm(n2, mu2, sigma2)
X <- rbind(X1, X2)
plot(X)
n1 <- 300
mu1 <- c(0, 0)
sigma1 <- matrix(c(1, 0.5, 0.5, 1), nrow=2, byrow=TRUE)
X1 <- mvtnorm::rmvnorm(n1, mu1, sigma1)
n2 <- 500
mu2 <- c(1, 1.5)
sigma2 <- matrix(c(1, -0.7, -0.7, 1), nrow=2, byrow=TRUE)
X2 <- mvtnorm::rmvnorm(n2, mu2, sigma2)
X <- rbind(X1, X2)
plot(X)
obj <- mvn_mix(X, K=1:5, verbose=TRUE, crit=c("aic", "bic", "hqic"))
# Fit mixture models for 1 to 3 compoenents
obj <- mvn_mix(X, K=1:3, verbose=TRUE, crit=c("aic", "bic", "hqic"))
plot(1:5, obj$aic, type='o', col="orange")
lines(1:5, obj$bic, col="dodgerblue")
lines(1:5, obj$hqic, col="firebrick")
# Fit mixture models for 1 to 3 compoenents
obj <- mvn_mix(X, K=1:3, epsilon=c(1e-6, 1e-6, 1e-5), verbose=TRUE, crit=c("aic", "bic", "hqic"))
warnings()
K = c(1, 3, 5, 7)
k = 3
which(K == k)
obj
plot(1:3, obj$aic, type='l', col="orange")
lines(1:3, obj$bic, col="dodgerblue")
lines(1:3, obj$hqic, col="firebrick")
legend("bottomleft", c("aic", "bic", "hqic"), lwd=2, col=c("orange", "dodgerblue", "firebrick"))
# Fit mixture models for 1 to 3 compoenents
obj <- mvn_mix(X, K=1:3, epsilon=1e-3, verbose=TRUE, crit=c("aic", "bic", "hqic"))
plot(1:3, obj$aic, type='l', col="orange")
lines(1:3, obj$bic, col="dodgerblue")
lines(1:3, obj$hqic, col="firebrick")
document()
=======
tmp <- lp(theta0, x, y)
}
plot(m)
plot(x, m)
m
beta1
beta2
beta1 = -0.5
beta2 = 4
m <- beta1 + beta2 * x^2
log(1/2)
image(R)
image(S)
lp <- function(theta, x, y){
kappa <- exp(theta[1])
nu    <- exp(theta[2])*0 + 1.2
phi   <- exp(theta[3])
beta1 <- theta[4]
beta2 <- theta[5]
m <- beta1 + beta2 * x^2
S <- makeR(x, kappa, nu, phi)
res <- dmvnorm(y, m, S, log=TRUE)
res <- res + sum(dt(c(kappa, phi)/100, 5, log=TRUE))
res <- res + sum(dnorm(c(beta1, beta2), 0, 100, log=TRUE))
return(res)
}
tmp <- -Inf
while(tmp == -Inf){
theta0 <- c(runif(3, -1, 1), -0.5, 4)
tmp <- lp(theta0, x, y)
}
kappa <- exp(theta[1])
nu    <- exp(theta[2])*0 + 1.2
phi   <- exp(theta[3])
beta1 <- theta[4]
beta2 <- theta[5]
m <- beta1 + beta2 * x^2
S <- makeR(x, kappa, nu, phi)
S
image(S)
S
h
makeR <- function(x1, kappa, nu, phi, x2=NULL,tau=1e-7){
if(is.null(x2)){
x2 <- x1
}
R <- matrix(1, nrow=length(x1), ncol=length(x2))
for(ii in 1:length(x1)){
for(jj in 1:length(x2)){
h <- sqrt(sum((x1[ii] - x2[ii])^2))
R[ii,jj] <- matern.covariance(h, kappa, nu, phi) + tau^2
}
}
return(R)
}
lp <- function(theta, x, y){
kappa <- exp(theta[1])
nu    <- exp(theta[2])
phi   <- exp(theta[3])
beta1 <- theta[4]
beta2 <- theta[5]
m <- beta1 + beta2 * x^2
S <- makeR(x, kappa, nu, phi)
res <- dmvnorm(y, m, S, log=TRUE)
res <- res + sum(dt(c(kappa, phi)/100, 5, log=TRUE))
res <- res + sum(dnorm(c(beta1, beta2), 0, 100, log=TRUE))
return(res)
}
tmp <- -Inf
while(tmp == -Inf){
theta0 <- c(runif(3, -1, 1), -0.5, 4)
tmp <- lp(theta0, x, y)
}
tmp
library(rSPDE)
library(MHadaptive)
library(mvtnorm)
#Simulate data
ff <- function(x){
x <- 0.5 + 2*x
sin(10*pi*x)/(2*x) + (x-1)^4
#x*sin(x*10)
}
n <- 100
x <- seq(0, 1, length.out=n)
y <- ff(x)
curve(ff(x), n=1001)
points(x, y, pch=16, col='orange', cex=1.5)
# 2. Write log posterior
#' theta has components
#' kappa = range parameter l = sqrt(1/kappa) is the length-scale
#' nu    = smoothness parameter
#' phi   = marginal spatial scale (phi^2 is variance; phi called sigma in rSPDE::matern.covariance function)
makeR <- function(x1, kappa, nu, phi, x2=NULL,tau=1e-7){
if(is.null(x2)){
x2 <- x1
}
R <- matrix(1, nrow=length(x1), ncol=length(x2))
for(ii in 1:length(x1)){
for(jj in 1:length(x2)){
h <- sqrt(sum((x1[ii] - x2[ii])^2))
R[ii,jj] <- matern.covariance(h, kappa, nu, phi) + tau^2
}
}
return(R)
}
lp <- function(theta, x, y){
kappa <- exp(theta[1])
nu    <- exp(theta[2])
phi   <- exp(theta[3])
beta1 <- theta[4]
beta2 <- theta[5]
m <- beta1 + beta2 * x^2
S <- makeR(x, kappa, nu, phi)
res <- dmvnorm(y, m, S, log=TRUE)
res <- res + sum(dt(c(kappa, phi)/100, 5, log=TRUE))
res <- res + sum(dnorm(c(beta1, beta2), 0, 100, log=TRUE))
return(res)
}
tmp <- -Inf
while(tmp == -Inf){
theta0 <- c(runif(3, -1, 1), -0.5, 4)
tmp <- lp(theta0, x, y)
}
S
kappa <- exp(theta[1])
nu    <- exp(theta[2])
phi   <- exp(theta[3])
beta1 <- theta[4]
beta2 <- theta[5]
m <- beta1 + beta2 * x^2
S <- makeR(x, kappa, nu, phi)
S
image(S)
makeR <- function(x1, kappa, nu, phi, x2=NULL,tau=1e-7){
if(is.null(x2)){
x2 <- x1
}
R <- matrix(1, nrow=length(x1), ncol=length(x2))
for(ii in 1:length(x1)){
for(jj in 1:length(x2)){
h <- sqrt(sum((x1[ii] - x2[jj])^2))
R[ii,jj] <- matern.covariance(h, kappa, nu, phi) + tau^2
}
}
return(R)
}
lp <- function(theta, x, y){
kappa <- exp(theta[1])
nu    <- exp(theta[2])
phi   <- exp(theta[3])
beta1 <- theta[4]
beta2 <- theta[5]
m <- beta1 + beta2 * x^2
S <- makeR(x, kappa, nu, phi)
res <- dmvnorm(y, m, S, log=TRUE)
res <- res + sum(dt(c(kappa, phi)/100, 5, log=TRUE))
res <- res + sum(dnorm(c(beta1, beta2), 0, 100, log=TRUE))
return(res)
}
tmp <- -Inf
while(tmp == -Inf){
theta0 <- c(runif(3, -1, 1), -0.5, 4)
tmp <- lp(theta0, x, y)
}
tmp
theta0 <- c(runif(3, -1, 1), -0.5, 4)
tmp <- lp(theta0, x, y)
tmp
theta0 <- c(0, 0, 0, -0.5, 4)
tmp <- lp(theta0, x, y)
tmp
fit <- Metro_Hastings(lp, theta0)
fit <- Metro_Hastings(lp, theta0m, x=x, y=y)
fit <- Metro_Hastings(lp, theta0, x=x, y=y)
fit <- Metro_Hastings(lp, theta0, x=x, y=y, iterations = 1000)
?lp
?Metro_Hastings
for(i in 1:1000) lp(theta0, x, y)
for(i in 1:4) lp(theta0, x, y)
lp(theta0, x, y)
for(i in 1:4) lp(theta0, x, y)
n <- 20
x <- seq(0, 1, length.out=n)
y <- ff(x)
curve(ff(x), n=1001)
points(x, y, pch=16, col='orange', cex=1.5)
makeR <- function(x1, kappa, nu, phi, x2=NULL,tau=1e-7){
if(is.null(x2)){
x2 <- x1
}
R <- matrix(1, nrow=length(x1), ncol=length(x2))
for(ii in 1:length(x1)){
for(jj in 1:length(x2)){
h <- sqrt(sum((x1[ii] - x2[jj])^2))
R[ii,jj] <- matern.covariance(h, kappa, nu, phi) + tau^2
}
}
return(R)
}
lp <- function(theta, x, y){
kappa <- exp(theta[1])
nu    <- exp(theta[2])
phi   <- exp(theta[3])
beta1 <- theta[4]
beta2 <- theta[5]
m <- beta1 + beta2 * x^2
S <- makeR(x, kappa, nu, phi)
res <- dmvnorm(y, m, S, log=TRUE)
res <- res + sum(dt(c(kappa, phi)/100, 5, log=TRUE))
res <- res + sum(dnorm(c(beta1, beta2), 0, 100, log=TRUE))
return(res)
}
theta0 <- c(0, 0, 0, -0.5, 4)
fit <- Metro_Hastings(lp, theta0, x=x, y=y)
ts,plot(fi$trace[,1])
ts,plot(fi$trace[,1])ts.plot(fit$trace[,1])
ts.plot(fit$trace[,1])
thetap <- fit$trace
kappa <- exp(thetap[,1])
nu    <- exp(thetap[,2])
phi   <- exp(thetap[,3])
phi
lambda <- phi^2*kappa^(2*nu)
ts.plot(lambda)
kappa <- exp(thetap[,1])
nu    <- exp(thetap[,2])
phi   <- exp(thetap[,3])
lambda <- phi^2*kappa^(2*nu)
ts.plot(lambda)
hist(lambda)
hist(lambda, breaks=50)
res <- 0
tmp <- 0
for(i in 0:1000){
tmp <- tmp + dpois(i, m*lambda)
}
m <- 1000
lambda <- 1
res <- 0
tmp <- 0
for(i in 0:1000){
tmp <- tmp + dpois(i, m*lambda)
}
tmp
for(i in 0:2000){
tmp <- tmp + dpois(i, m*lambda)
}
tmp
m <- 1000
lambda <- 1
res <- 0
tmp <- 0
for(i in 0:2000){
tmp <- tmp + dpois(i, m*lambda)
}
tmp
dbinom(0, 1, .4)
dbinom(0, 0, .4)
dbinom(1, 0, .4)
dbinom(5, 0, .4)
z <- 5
res <- 0
tmp <- 0
for(i in 0:2000){
tmp <- tmp + dpois(i, m*lambda)
res <- res + z*dpois(i, m*lambda)*dbinom(z, i, 1/m)/i
}
res
res
for(i in 1:2000){
tmp <- tmp + dpois(i, m*lambda)
res <- res + z*dpois(i, m*lambda)*dbinom(z, i, 1/m)/i
}
m <- 1000
lambda <- 1
z <- 5
res <- 0
tmp <- 0
for(i in 1:2000){
tmp <- tmp + dpois(i, m*lambda)
res <- res + z*dpois(i, m*lambda)*dbinom(z, i, 1/m)/i
}
res
dpois(5, 1)
m <- 1000
lambda <- 1
z <- 5
res <- 0
tmp <- 0
for(i in 1:3000){
tmp <- tmp + dpois(i, m*lambda)
res <- res + z*dpois(i, m*lambda)*dbinom(z, i, 1/m)/i
}
res
185-(299*3)/1000
1185-(299*3)
library(devtools)
library(roxygen2)
document()
library(plyr)
?ggsummary
df <- data.frame(foo = sample(c("a", "b", "c"), 100),
fie = rpois(100, 0.5))
df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
df <- data.frame(foo = sample(c("a", "b", "c"), 100, replace=TRUE),
fie = rpois(100, 0.5))
df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
set.seed(111);df <- data.frame(foo = sample(c("a", "b", "c"), 100, replace=TRUE),
fie = rpois(100, 0.5))
df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
library(tidyverse)
ggplot(summ, x=fie, y=y, fill=foo)
set.seed(111);df <- data.frame(foo = sample(c("a", "b", "c"), 100, replace=TRUE),
fie = rpois(100, 0.5))
df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
summ <- ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
df
summ
set.seed(111);df <- data.frame(foo = sample(c("a", "b", "c"), 100, replace=TRUE),
fie = rpois(100, 0.5))
df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
summ <- ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
set.seed(111);df <- data.frame(foo = sample(c("a", "b", "c"), 100, replace=TRUE),
fie = rpois(100, 0.5))
df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
df
df$y
ggsummary(df, measurevar="y")
set.seed(111);df <- data.frame(foo = sample(c("a", "b", "c"), 100, replace=TRUE),
fie = rpois(100, 0.5))
df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
set.seed(111)
df <- data.frame(foo = sample(c("a", "b", "c"), 100),
fie = rpois(100, 0.5))
set.seed(111);df <- data.frame(foo = sample(c("a", "b", "c"), 100, replace=TRUE),
fie = rpois(100, 0.5))
df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
df <- data.frame(foo = sample(c("a", "b", "c"), 100),
fie = rpois(100, 0.5), replace=TRUE)
df <- data.frame(foo = sample(c("a", "b", "c"), 100, replace=TRUE),
fie = rpois(100, 0.5))
df
df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
df
names(df)
ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
library(plyr)
ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
measurevar="y"
groupvars=c("foo", "fie")
# New version of length which can handle NA's: if na.rm==T, don't count them
length2 <- function (x, na.rm=FALSE) {
if (na.rm) sum(!is.na(x))
else       length(x)
}
# This does the summary. For each group's data frame, return a vector with
# N, mean, and sd
datac <- plyr::ddply(data, groupvars, .drop=.drop,
.fun = function(xx, col) {
c(N    = length2(xx[[col]], na.rm=na.rm),
mean = mean   (xx[[col]], na.rm=na.rm),
sd   = sd     (xx[[col]], na.rm=na.rm)
)
},
measurevar
)
# This does the summary. For each group's data frame, return a vector with
# N, mean, and sd
datac <- plyr::ddply(data, groupvars, .drop=.drop,
.fun = function(xx, col) {
c(N    = length2(xx[[col]], na.rm=na.rm),
mean = mean   (xx[[col]], na.rm=na.rm),
sd   = sd     (xx[[col]], na.rm=na.rm)
)
},
measurevar
)
table(df$foo, df$fie)
set.seed(111);df <- data.frame(foo = sample(c("a", "b", "c"), 100, replace=TRUE),
fie = rpois(100, 0.5))
df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
set.seed(1111);df <- data.frame(foo = sample(c("a", "b", "c"), 100, replace=TRUE),
fie = rpois(100, 0.5))
df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
set.seed(11111);df <- data.frame(foo = sample(c("a", "b", "c"), 100, replace=TRUE),
fie = rpois(100, 0.5))
df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
last_error()
rlang
library(rlang)
last_error()
#' df <- data.frame(foo = sample(c("a", "b", "c"), 100, replace=TRUE),
#'                  fie = rpois(100, 0.5))
#' df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
#'         rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
#'         rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
#'
#' summ <- ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
#' #ggplot2
#'
#' @export
ggsummary <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
conf.interval=.95, .drop=TRUE) {
# New version of length which can handle NA's: if na.rm==T, don't count them
length2 <- function (x, na.rm=FALSE) {
if (na.rm) sum(!is.na(x))
else       length(x)
}
# This does the summary. For each group's data frame, return a vector with
# N, mean, and sd
datac <- plyr::ddply(data, groupvars, .drop=.drop,
.fun = function(xx, col) {
c(N    = length2(xx[[col]], na.rm=na.rm),
mean = mean   (xx[[col]], na.rm=na.rm),
sd   = sd     (xx[[col]], na.rm=na.rm)
)
},
measurevar
)
# Rename the "mean" column
#datac <- rename(datac, c("mean" = measurevar))
datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
# Confidence interval multiplier for standard error
# Calculate t-statistic for confidence interval:
# e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
ciMult <- qt(conf.interval/2 + .5, datac$N-1)
datac$ci <- datac$se * ciMult
return(datac)
}
document()
set.seed(111)
?ggsummary
set.seed(111)
df <- data.frame(foo = sample(c("a", "b", "c"), 100, replace=TRUE),
fie = rpois(100, 0.5))
df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
summ <- ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
summ
ggplot(summ1, aes(x=fie, y=y, fill=foo)) +
geom_bar(position=position_dodge2(padding=0.1), stat="identity") +
geom_errorbar(aes(ymin=y-ci, ymax=y+ci),
width=.05,                    # Width of the error bars
position=position_dodge(.45)) +
title("hello")
ggplot(summ, aes(x=fie, y=y, fill=foo)) +
geom_bar(position=position_dodge2(padding=0.1), stat="identity") +
geom_errorbar(aes(ymin=y-ci, ymax=y+ci),
width=.05,                    # Width of the error bars
position=position_dodge(.45))
summ <- ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
summ
ggplot(summ1, aes(x=fie, y=mean, fill=foo)) +
geom_bar(position=position_dodge2(padding=0.1), stat="identity") +
geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci),
width=.05,                    # Width of the error bars
position=position_dodge(.45)) +
title("dslsj)")
ggplot(summ, aes(x=fie, y=mean, fill=foo)) +
geom_bar(position=position_dodge2(padding=0.1), stat="identity") +
geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci),
width=.05,                    # Width of the error bars
position=position_dodge(.45))
ggplot(summ, aes(x=fie, y=mean, fill=foo)) +
geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci))
ggplot(summ, aes(x=fie, y=mean, fill=foo)) +
geom_bar(position=position_dodge2(padding=0.1), stat="identity") +
geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci),
width=.05,                    # Width of the error bars
position=position_dodge(.9))
document()
?ggsumm
?ggsummary
summ
document()
library(quack)
library(quack)
>>>>>>> 48416ede74f016a3a1ee34dbe9fe81d93a2c95aa
