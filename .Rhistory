ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
measurevar="y"
groupvars=c("foo", "fie")
# New version of length which can handle NA's: if na.rm==T, don't count them
length2 <- function (x, na.rm=FALSE) {
if (na.rm) sum(!is.na(x))
else       length(x)
}
# This does the summary. For each group's data frame, return a vector with
# N, mean, and sd
datac <- plyr::ddply(data, groupvars, .drop=.drop,
.fun = function(xx, col) {
c(N    = length2(xx[[col]], na.rm=na.rm),
mean = mean   (xx[[col]], na.rm=na.rm),
sd   = sd     (xx[[col]], na.rm=na.rm)
)
},
measurevar
)
# This does the summary. For each group's data frame, return a vector with
# N, mean, and sd
datac <- plyr::ddply(data, groupvars, .drop=.drop,
.fun = function(xx, col) {
c(N    = length2(xx[[col]], na.rm=na.rm),
mean = mean   (xx[[col]], na.rm=na.rm),
sd   = sd     (xx[[col]], na.rm=na.rm)
)
},
measurevar
)
table(df$foo, df$fie)
set.seed(111);df <- data.frame(foo = sample(c("a", "b", "c"), 100, replace=TRUE),
fie = rpois(100, 0.5))
df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
set.seed(1111);df <- data.frame(foo = sample(c("a", "b", "c"), 100, replace=TRUE),
fie = rpois(100, 0.5))
df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
set.seed(11111);df <- data.frame(foo = sample(c("a", "b", "c"), 100, replace=TRUE),
fie = rpois(100, 0.5))
df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
last_error()
rlang
library(rlang)
last_error()
#' df <- data.frame(foo = sample(c("a", "b", "c"), 100, replace=TRUE),
#'                  fie = rpois(100, 0.5))
#' df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
#'         rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
#'         rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
#'
#' summ <- ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
#' #ggplot2
#'
#' @export
ggsummary <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
conf.interval=.95, .drop=TRUE) {
# New version of length which can handle NA's: if na.rm==T, don't count them
length2 <- function (x, na.rm=FALSE) {
if (na.rm) sum(!is.na(x))
else       length(x)
}
# This does the summary. For each group's data frame, return a vector with
# N, mean, and sd
datac <- plyr::ddply(data, groupvars, .drop=.drop,
.fun = function(xx, col) {
c(N    = length2(xx[[col]], na.rm=na.rm),
mean = mean   (xx[[col]], na.rm=na.rm),
sd   = sd     (xx[[col]], na.rm=na.rm)
)
},
measurevar
)
# Rename the "mean" column
#datac <- rename(datac, c("mean" = measurevar))
datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
# Confidence interval multiplier for standard error
# Calculate t-statistic for confidence interval:
# e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
ciMult <- qt(conf.interval/2 + .5, datac$N-1)
datac$ci <- datac$se * ciMult
return(datac)
}
document()
set.seed(111)
?ggsummary
set.seed(111)
df <- data.frame(foo = sample(c("a", "b", "c"), 100, replace=TRUE),
fie = rpois(100, 0.5))
df$y <- rnorm(100, df$fie + 1, 0.1)*(df$foo == "a") +
rnorm(100, df$fie + 2, 0.1)*(df$foo == "b") +
rnorm(100, df$fie + 3, 0.1)*(df$foo == "c")
summ <- ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
summ
ggplot(summ1, aes(x=fie, y=y, fill=foo)) +
geom_bar(position=position_dodge2(padding=0.1), stat="identity") +
geom_errorbar(aes(ymin=y-ci, ymax=y+ci),
width=.05,                    # Width of the error bars
position=position_dodge(.45)) +
title("hello")
ggplot(summ, aes(x=fie, y=y, fill=foo)) +
geom_bar(position=position_dodge2(padding=0.1), stat="identity") +
geom_errorbar(aes(ymin=y-ci, ymax=y+ci),
width=.05,                    # Width of the error bars
position=position_dodge(.45))
summ <- ggsummary(df, measurevar = "y", groupvars = c("foo", "fie"))
summ
ggplot(summ1, aes(x=fie, y=mean, fill=foo)) +
geom_bar(position=position_dodge2(padding=0.1), stat="identity") +
geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci),
width=.05,                    # Width of the error bars
position=position_dodge(.45)) +
title("dslsj)")
ggplot(summ, aes(x=fie, y=mean, fill=foo)) +
geom_bar(position=position_dodge2(padding=0.1), stat="identity") +
geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci),
width=.05,                    # Width of the error bars
position=position_dodge(.45))
ggplot(summ, aes(x=fie, y=mean, fill=foo)) +
geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci))
ggplot(summ, aes(x=fie, y=mean, fill=foo)) +
geom_bar(position=position_dodge2(padding=0.1), stat="identity") +
geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci),
width=.05,                    # Width of the error bars
position=position_dodge(.9))
document()
?ggsumm
?ggsummary
summ
document()
library(quack)
library(quack)
>>>>>>> 48416ede74f016a3a1ee34dbe9fe81d93a2c95aa
library(quack)
install.packages("mathart")
Sys.setenv('http_proxy'='http://proxyout.lanl.gov:8080')
Sys.setenv('https_proxy'='http://proxyout.lanl.gov:8080')
install.packages("mathart")
library(mathart)
?nn2
foo = c(1, 3)
names(foo) <- c("a", "b")
foo
?slapGP
library(quack)
?slapGP
slapGP
?nn2
curve(x^2/1000)
curve(x^2/1000, to=1000)
curve(log(x/1000))
curve(log(x)/1000)
curve(log(1+x)/1000)
curve(log(1+x)/1000, to=1000)
curve(0.1*floor(x*100))
curve(0.1*floor(x*100), to=1000)
curve(0.1*floor(x*100), to=100)
curve(0.1*floor(x*100), to=500)
curve(floor(x*100), to=500)
curve(0.1*floor(x/100), to=500)
#Find nearest hub using kd-tree
#browser()
NH <- RANN::nn2(H, matrix(Xnew, nrow=1), k=1,
searchtype = ifelse(x < 100, "standard", "priority"), eps = 0.1*floor(x/100))
document()
library(quack)
slapGP
nrow(H)
library(quack)
library(quack)
#Make prediction and return hubs unmodified
kvec <- rep(NA, n)
library(tgp)
?predict.tgp
X <- smartLHS(40, 2)
library(lhs)
X <- smartLHS(40, 2)
y <- apply(X, 1, duqling::dms_additive)
tmp <- btgpllm(X, y)
predict(tmp, X[1,])
predict(tmp, matrix(X[1,], nrow=1))
foo = predict(tmp, matrix(X[1,], nrow=1))
foo$XX
X[1,]
foo$R
?btgp
foo$ZZ.mean
foo$ZZ.s2
predict(tmp, matrix(X[1,], nrow=1), pred.n=FALSE)
tmp <- btgpllm(X, y, pred.n=FALSE)
foo = predict(tmp, matrix(X[1,], nrow=1))
foo$ZZ.s2
foo$ZZ.mean
library(quack)
library(roxygen2)
document()
library(devtools)
document()
?mvn_mix
document()
?mvn_mix
document()
n
X
ind <- sample(n, minibatch, replace=FALSE)
n = 1500
minibatch=1500
ind <- sample(n, minibatch, replace=FALSE)
sub_samp <- sample(n, minibatch, replace=FALSE)
sub_samp
library(quack)
document()
library(devtools)
library(roxygen2)
document()
library(quack)
library(quack)
library(MHadaptive)
library(devtools)
library(roxygen2)
document()
library(quack)
library(mvtnorm)
X <- rbind(rmvnorm(250, c(0, 0), matrix(c(1, 0.3, 0.3, 1), nrow=2)),
rmvnorm(250, c(1, 1), matrix(c(1, -0.7, -0.7, 1), nrow=2)))
plot(X)
library(quack)
library(mvtnorm)
library(quack)
X <- rbind(rmvnorm(250, c(0, 0), matrix(c(1, 0.3, 0.3, 1), nrow=2)),
rmvnorm(250, c(1, 1), matrix(c(1, -0.7, -0.7, 1), nrow=2)))
plot(X)
mix <- mvn_mix(X, 2)
document()
?mvn_mix
mvn_mix
mix <- mvn_mix(X, 2)
mix <- mvn_mix(X, 2, verbose=TRUE)
mix <- mvn_mix(X, 2, verbose=TRUE, minibatch=100)
k = 1
K = 1
document()
mix <- mvn_mix(X, 2, verbose=TRUE, minibatch=100)
document()
mix <- mvn_mix(X, 2, verbose=TRUE, minibatch=100)
Inf > -Inf
mix <- mvn_mix(X, 2, verbose=TRUE, minibatch=100)
document()
mix <- mvn_mix(X, 2, verbose=TRUE, minibatch=100)
document()
mix <- mvn_mix(X, 2, verbose=TRUE, minibatch=100)
mix <- mvn_mix(X, 2, verbose=TRUE, minibatch=100)
document()
mix <- mvn_mix(X, 2, verbose=TRUE, minibatch=100)
K = 2
kappa = 0.75
epsilon = 0.001
max_iter = 2000
verbose=TRUE
print_iter = 10
crit  = "bic"
if(length(epsilon) == 1){
epsilon <- rep(epsilon, length(K))
}
if(length(epsilon) != length(K)){
stop("epsilon should be either scalar or a vector of length = length(K)")
}
if(minibatch < nrow(X)){
if(max(epsilon) > -Inf){
warning("Stochastic EM algorithm with minibatching ignores epsilon. Set epsilon = -Inf to ignore this message")
epsilon <- rep(-Inf, length(K))
}
}
minibatch = 100
nrw(X)
if(verbose){
cat("Number of components:", k)
}
kK = 2
K = 2
k =2
if(verbose){
cat("Number of components:", k)
}
N_comp <- k
# Initialize model
SX <- cov(X)
a_n <- function(n, kap=0.75) n^(-kap)
pi <- (tmp <- runif(N_comp))/sum(tmp)
mu <- sigma <- list()
for(j in 1:N_comp){
mu[[j]]    <- X[sample(nrow(X), 1),]
sigma[[j]] <- rWishart(1, df=ncol(X)+2, SX)[,,1]
}
n <- nrow(X)
p <- N_comp
d <- nrow(SX)
pi_ij <- matrix(0, nrow=n, ncol=p)
n
d
iter <- 1
tol <- Inf
log_lik <- rep(NA, max_iter)
eps0 <- epsilon[which(K==k)]
tol > eps0 & iter < max_iter
sub_samp <- sample(n, minibatch, replace=FALSE)
sub_samp
#E-STEP
for(i in sub_samp){
for(j in 1:p){
xi <- X[i,]
pi_ij[i,j] <- pi[j] * dmvnorm(as.numeric(xi), as.numeric(mu[[j]]), sigma[[j]])
}
}
pi_ij
pi
pi_ij
for(i in sub_samp){
pi_ij[i,] <- pi_ij[i,]/sum(pi_ij[i,])
}
pi_ij
# M-STEP
Sj <- list()
for(j in 1:p){
tmp <- matrix(0, nrow=d, ncol=d)
for(i in sub_samp){
xi <- X[i,]
tmp <- tmp + pi_ij[i,j]*tcrossprod(xi - mu[[j]])
}
Sj[[j]] <- tmp
}
Sj
Sx
SX
#Update component probabilities
pi <- apply(pi_ij, 2, mean)
#Update covariance matrices
for(j in 1:p){
sigma[[j]] <- (2*a_n(n)*SX + Sj[[j]])/(2*a_n(n) + n*pi[j])
}
sigma
a_n(n)
#Update mean vectors
for(j in 1:p){
tmp <- 0
for(i in sub_samp){
xi <- X[i,]
tmp <- tmp + pi_ij[i,j]*xi
}
mu[[j]] <- tmp/(n*pi[j])
}
mu
#Compute log likelihood
log_lik[iter] <- 0
for(i in sub_samp){
tmp <- 0
xi <- X[i,]
for(j in 1:p){
tmp <- tmp + pi[j]*dmvnorm(xi, mu[[j]], sigma[[j]])
}
log_lik[iter] <- log_lik[iter] + log(tmp) + log(n) - log(minibatch)
}
log_lik[iter]
while(tol > eps0 & iter < max_iter){
sub_samp <- sample(n, minibatch, replace=FALSE)
#E-STEP
for(i in sub_samp){
for(j in 1:p){
xi <- X[i,]
pi_ij[i,j] <- pi[j] * dmvnorm(as.numeric(xi), as.numeric(mu[[j]]), sigma[[j]])
}
}
for(i in sub_samp){
pi_ij[i,] <- pi_ij[i,]/sum(pi_ij[i,])
}
# M-STEP
Sj <- list()
for(j in 1:p){
tmp <- matrix(0, nrow=d, ncol=d)
for(i in sub_samp){
xi <- X[i,]
tmp <- tmp + pi_ij[i,j]*tcrossprod(xi - mu[[j]])
}
Sj[[j]] <- tmp
}
#Update component probabilities
pi <- apply(pi_ij, 2, mean)
#Update covariance matrices
for(j in 1:p){
sigma[[j]] <- (2*a_n(n, kappa)*SX + Sj[[j]])/(2*a_n(n, kappa) + n*pi[j])
}
#Update mean vectors
for(j in 1:p){
tmp <- 0
for(i in sub_samp){
xi <- X[i,]
tmp <- tmp + pi_ij[i,j]*xi
}
mu[[j]] <- tmp/(n*pi[j])
}
#Compute log likelihood
log_lik[iter] <- 0
for(i in sub_samp){
tmp <- 0
xi <- X[i,]
for(j in 1:p){
tmp <- tmp + pi[j]*dmvnorm(xi, mu[[j]], sigma[[j]])
}
log_lik[iter] <- log_lik[iter] + log(tmp) + log(n) - log(minibatch)
}
if((iter %% print_iter) == 0){
if(verbose)
cat("\nIteration:", iter, ", tol:", tol, ", log-lik:", log_lik[iter])
}
if(iter > 1){
tol <- log_lik[iter] - log_lik[iter - 1]
}
print(log_lik[iter])
iter <- iter + 1
}
iter
log_lik
log_lik[1:5]
tol > eps0 & iter < max_iter
tol
eps0
epsilon
epsilon = -Inf
eps0 <- epsilon[which(K==k)]
while(tol > eps0 & iter < max_iter){
sub_samp <- sample(n, minibatch, replace=FALSE)
#E-STEP
for(i in sub_samp){
for(j in 1:p){
xi <- X[i,]
pi_ij[i,j] <- pi[j] * dmvnorm(as.numeric(xi), as.numeric(mu[[j]]), sigma[[j]])
}
}
for(i in sub_samp){
pi_ij[i,] <- pi_ij[i,]/sum(pi_ij[i,])
}
# M-STEP
Sj <- list()
for(j in 1:p){
tmp <- matrix(0, nrow=d, ncol=d)
for(i in sub_samp){
xi <- X[i,]
tmp <- tmp + pi_ij[i,j]*tcrossprod(xi - mu[[j]])
}
Sj[[j]] <- tmp
}
#Update component probabilities
pi <- apply(pi_ij, 2, mean)
#Update covariance matrices
for(j in 1:p){
sigma[[j]] <- (2*a_n(n, kappa)*SX + Sj[[j]])/(2*a_n(n, kappa) + n*pi[j])
}
#Update mean vectors
for(j in 1:p){
tmp <- 0
for(i in sub_samp){
xi <- X[i,]
tmp <- tmp + pi_ij[i,j]*xi
}
mu[[j]] <- tmp/(n*pi[j])
}
#Compute log likelihood
log_lik[iter] <- 0
for(i in sub_samp){
tmp <- 0
xi <- X[i,]
for(j in 1:p){
tmp <- tmp + pi[j]*dmvnorm(xi, mu[[j]], sigma[[j]])
}
log_lik[iter] <- log_lik[iter] + log(tmp) + log(n) - log(minibatch)
}
if((iter %% print_iter) == 0){
if(verbose)
cat("\nIteration:", iter, ", tol:", tol, ", log-lik:", log_lik[iter])
}
if(iter > 1){
tol <- log_lik[iter] - log_lik[iter - 1]
}
print(log_lik[iter])
iter <- iter + 1
}
document()
sigma
mu
mvn_mix(X, 2, epsilon = .01)
mvn_mix(X, 2, epsilon = .001)
mvn_mix(X, 2, epsilon = .0001)
mvn_mix(X, 2, epsilon = -Inf, minibatch = 200)
document()
mvn_mix(X, 2, epsilon = -Inf, minibatch = 200)
pi
document()
mvn_mix(X, 2, epsilon = -Inf, minibatch = 200)
mvn_mix(X, 2)
plot(X)
mvn_mix(X, 2)
1/500^.75
mvn_mix(X, 2, kappa=2)
document()
