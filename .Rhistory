beta <- 2
kappa_vec <- c(0.1, 1, 5, 10)
par(mfrow=c(2,2))
for(k in seq_along(kappa_vec)){
kap <- kappa_vec[k]
x <- regamma(10000, alpha, beta, kap)
hist(x, freq=FALSE, breaks=40, main=paste(expression(paste(kappa, " = ")), kap))
curve(degamma(x, alpha, beta, kap), add=TRUE, lwd=3, col="orange")
curve(dgamma(x, alpha, beta), add=TRUE, lwd=3, col="dodgerblue")
curve(dgamma(x, alpha+1, beta), add=TRUE, lwd=3, col="firebrick")
w <- beta^-alpha/(beta^-alpha - (beta + kap)^-alpha)
lambda <- alpha*w*(1 - ((w-1)/w)^(1/alpha + 1)) - alpha
curve(dgamma(x, alpha+lambda, beta), add=TRUE, lwd=3, lty=3, col="sienna")
legend("topright", c(expression(paste("Gamma(", alpha, ", ", beta, ")")),
expression(paste("Gamma(", alpha, "+1, ", beta, ")")),
expression(paste("Gamma(", alpha, "+", lambda, ", ", beta, ")")),
expression(paste("IMGam(", alpha, ", ", beta, ", ", kappa, ")"))),
lwd=3, lty=c(1, 1, 3, 1), col=c("dodgerblue", "firebrick", "sienna", "orange"))
}
library(GBASS)
?qbass
motorcyle
mcycle
MASS::motorcycle
1e3
?Density
?density
K = 2
kappa = 0.75
epsilon=1e-5
max_iter=2000
verbose=TRUE
print_iter=10
crit=NULL
minibatch=nrow(X)
X <- rgamma(100, 3, 1.4)
X <- matrix(rgamma(100, 3, 1.4), ncol=1)
X
minibatch = nrow(X)
minibatch
if(length(epsilon) == 1){
epsilon <- rep(epsilon, length(K))
}
if(length(epsilon) != length(K)){
stop("epsilon should be either scalar or a vector of length = length(K)")
}
if(minibatch < nrow(X)){
if(max(epsilon) > -Inf){
warning("Stochastic EM algorithm with minibatching ignores epsilon. Set epsilon = -Inf to ignore this message")
epsilon <- rep(-Inf, length(K))
}
warning("Minibatch version of EM does not seem to work at this point. ")
}
out <- list()
cnt <- 1
-Inf > -Inf
k = 1
K
k = 2
if(verbose){
cat("Number of components:", k)
}
N_comp <- k
# Initialize model
SX <- cov(X)
a_n <- function(n, kap=0.75) n^(-kap)
pi <- (tmp <- runif(N_comp))/sum(tmp)
mu <- sigma <- list()
for(j in 1:N_comp){
mu[[j]]    <- X[sample(nrow(X), 1),]
sigma[[j]] <- rWishart(1, df=ncol(X)+2, SX)[,,1]
}
sigma
mu
n <- nrow(X)
p <- N_comp
d <- nrow(SX)
pi_ij <- matrix(0, nrow=n, ncol=p)
iter <- 1
tol <- Inf
log_lik <- rep(NA, max_iter)
eps0 <- epsilon[which(K==k)]
tol
tol > eps0 & iter < max_iter
sub_samp <- sample(n, minibatch, replace=FALSE)
#E-STEP
for(i in sub_samp){
for(j in 1:p){
xi <- X[i,]
pi_ij[i,j] <- pi[j] * dmvnorm(as.numeric(xi), as.numeric(mu[[j]]), sigma[[j]])
}
}
library(mvtnorm)
#E-STEP
for(i in sub_samp){
for(j in 1:p){
xi <- X[i,]
pi_ij[i,j] <- pi[j] * dmvnorm(as.numeric(xi), as.numeric(mu[[j]]), sigma[[j]])
}
}
as.numeric(mu[[1]])
p
sigma[[j]]
as.matrix(sigma[[j]])
as.matrix(matrix(runif(4), ncol=2))
(matrix(runif(4), ncol=2))
matrix(matrix(runif(4), ncol=2))
as.matrix(matrix(runif(4), ncol=2))
pi_ij[i,j] <- pi[j] * dmvnorm(as.numeric(xi), as.numeric(mu[[j]]), as.matrix(sigma[[j]]))
while(tol > eps0 & iter < max_iter){
sub_samp <- sample(n, minibatch, replace=FALSE)
#E-STEP
for(i in sub_samp){
for(j in 1:p){
xi <- X[i,]
pi_ij[i,j] <- pi[j] * dmvnorm(as.numeric(xi), as.numeric(mu[[j]]), as.matrix(sigma[[j]]))
}
}
for(i in sub_samp){
pi_ij[i,] <- pi_ij[i,]/sum(pi_ij[i,])
}
# M-STEP
Sj <- list()
for(j in 1:p){
tmp <- matrix(0, nrow=d, ncol=d)
for(i in sub_samp){
xi <- X[i,]
tmp <- tmp + pi_ij[i,j]*tcrossprod(xi - mu[[j]])
}
Sj[[j]] <- tmp
}
#Update component probabilities
pi <- apply(pi_ij[sub_samp,], 2, mean)
#Update covariance matrices
for(j in 1:p){
sigma[[j]] <- (2*a_n(n, kappa)*SX + Sj[[j]])/(2*a_n(n, kappa) + n*pi[j])
}
#Update mean vectors
for(j in 1:p){
tmp <- 0
for(i in sub_samp){
xi <- X[i,]
tmp <- tmp + pi_ij[i,j]*xi
}
mu[[j]] <- tmp/(minibatch*pi[j])
}
#Compute log likelihood
log_lik[iter] <- log(n) - log(minibatch)
for(i in sub_samp){
tmp <- 0
xi <- X[i,]
for(j in 1:p){
tmp <- tmp + pi[j]*dmvnorm(xi, mu[[j]], sigma[[j]])
}
log_lik[iter] <- log_lik[iter] + log(tmp)
}
if((iter %% print_iter) == 0){
if(verbose)
cat("\nIteration:", iter, ", tol:", tol, ", log-lik:", log_lik[iter])
}
if(iter > 1){
tol <- log_lik[iter] - log_lik[iter - 1]
}
iter <- iter + 1
}
foo <- mvn_mix(X, K=1:10)
foo <- quack::mvn_mix(X, K=1:10)
document()
devtools::document()
library(devtools)
document()
document()
document()
document()
foo <- quack::mvn_mix(X, K=1:10)
document()
foo <- quack::mvn_mix(X, K=1:10)
names(foo)
foo
length(foo)
obj <- foo[[2]]
obj$pi
p <- length(obj$pi)
indx <- sample(n, p, obj$pi)
indx <- sample(n, p, replace=TRUE, obj$pi)
?sample
indx <- sample(p, n, replace=TRUE, obj$pi)
indx
table(indx)
rmvnorm(30,
mean=obj$mean[[indx[i]]],
as.matrix(obj$sigma[[indx[i]]]))
rmvnorm(30,
mean=obj$mu[[indx[i]]],
as.matrix(obj$sigma[[indx[i]]]))
for(i in 1:30) rmvnorm(1,
mean=obj$mu[[indx[i]]],
as.matrix(obj$sigma[[indx[i]]]))
for(i in 1:1000) rmvnorm(1,
mean=obj$mu[[indx[i]]],
as.matrix(obj$sigma[[indx[i]]]))
indx
obj <- foo[[5]]
p <- length(obj$pi)
indx <- sample(p, n, replace=TRUE, obj$pi)
res <- matrix(NA, nrow=n, ncol=p)
indx
table(indx)
p
n
n <- 1000
i = 1
j <- which(indx == i)
j
length(j)
cnt <- 0
max(cnt) + 1:length(j)
cnt
res[cnt,] <- rmvnorm(length(j),
mean=obj$mu[[i]],
as.matrix(obj$sigma[[i]]))
i = 2
j <- which(indx == i)
cnt <- max(cnt) + 1:length(j)
cnt
cnt
j
cnt <- 0
i = 1
j <- which(indx == i)
cnt <- max(cnt) + 1:length(j)
cnt
i = 2
j <- which(indx == i)
cnt <- max(cnt) + 1:length(j)
cnt
res <- matrix(NA, nrow=n, ncol=p)
cnt <- 0
for(i in 1:p){
j <- which(indx == i)
if(length(j) > 0){
cnt <- max(cnt) + 1:length(j)
res[cnt,] <- rmvnorm(length(j),
mean=obj$mu[[i]],
as.matrix(obj$sigma[[i]]))
}
}
res
length(indx)
n
n <- 1000
p <- length(obj$pi)
indx <- sample(p, n, replace=TRUE, obj$pi)
res <- matrix(NA, nrow=n, ncol=p)
cnt <- 0
for(i in 1:p){
j <- which(indx == i)
if(length(j) > 0){
cnt <- max(cnt) + 1:length(j)
res[cnt,] <- rmvnorm(length(j),
mean=obj$mu[[i]],
as.matrix(obj$sigma[[i]]))
}
}
res
cov(res)
dim(res)
sigma
obj$mu[[1]]
obj$sigma[[1]]
p <- length(obj$mu[[1]])
p
p <- length(obj$mu[[1]])
L <- length(obj$pi)
indx <- sample(L, n, replace=TRUE, obj$pi)
res <- matrix(NA, nrow=n, ncol=p)
cnt <- 0
for(i in 1:L){
j <- which(indx == i)
if(length(j) > 0){
cnt <- max(cnt) + 1:length(j)
res[cnt,] <- rmvnorm(length(j),
mean=obj$mu[[i]],
as.matrix(obj$sigma[[i]]))
}
}
res
# Shuffle indices
res <- res[sample(n,n,FALSE),]
rmvn_mix <- function(n, obj){
p <- length(obj$mu[[1]])
L <- length(obj$pi)
indx <- sample(L, n, replace=TRUE, obj$pi)
res <- matrix(NA, nrow=n, ncol=p)
cnt <- 0
for(i in 1:L){
j <- which(indx == i)
if(length(j) > 0){
cnt <- max(cnt) + 1:length(j)
res[cnt,] <- rmvnorm(length(j),
mean=obj$mu[[i]],
as.matrix(obj$sigma[[i]]))
}
}
# Shuffle indices
res <- res[sample(n,n,FALSE),]
return(res)
}
rmvn_mix(foo[[5]])
hist(rmvn_mix(1000, foo[[5]]))
hist(rmvn_mix(1000, foo[[5]]), freq=F)
curve(dgamma(x, 3, 1.4))
hist(rmvn_mix(1000, foo[[5]]), freq=F)
curve(dgamma(x, 3, 1.4), add=TRUE)
dmvn_mix <- function(x, obj, log=FALSE){
n <- length(x)
p <- length(obj$mu[[1]])
L <- length(obj$pi)
res <- matrix(0, nrow=n, ncol=p)
for(i in 1:n){
for(j in 1:L){
res[i] <- res[i] + obj$pi[j]*dmvnorm(x[i],
obj$mu[[j]],
as.matrix(obj$sigma[[j]]))
}
}
return(res)
}
dmvn_mix(2, obj)
dmvn_mix(seq(0, 6, by=0.2), obj)
document()
?dmvn_mix
library(quack)
Kmax
document()
devtools::document()
foo = rgamma(1000, 3, 2)
fits <- quack::mvn_mix(foo, K=c(1:2, 5))
fits <- quack::mvn_mix(matrix(foo, ncol=1), K=c(1:2, 5))
library(quack)
fits <- quack::mvn_mix(matrix(foo, ncol=1), K=c(1:2, 5))
library(mvtnorm)
fits <- quack::mvn_mix(matrix(foo, ncol=1), K=c(1:2, 5))
fits
length(fits)
fit$kvec
fits$kvec
#' plot(X)
#'
#' #Fit mixture models for 1 to 3 compoenents
#' obj <- mvn_mix(X, K=1:3, epsilon=1e-3, verbose=TRUE, crit=c("aic", "bic", "hqic"))
#'
#' plot(1:3, obj$aic, type='l', col="orange")
#' lines(1:3, obj$bic, col="dodgerblue")
#' lines(1:3, obj$hqic, col="firebrick")
#' legend("bottomleft", c("aic", "bic", "hqic"), lwd=2, col=c("orange", "dodgerblue", "firebrick"))
#' @export
mvn_mix <- function(X, K=1:3, kappa=0.75, epsilon=1e-5, max_iter=2000, verbose=TRUE, print_iter = 10, crit=c("aic", "bic", "hqic"),
minibatch=nrow(X)){
if(length(dim(X)) != 2){
stop("X must be a matrix")
}
if(length(epsilon) == 1){
epsilon <- rep(epsilon, length(K))
}
if(length(epsilon) != length(K)){
stop("epsilon should be either scalar or a vector of length = length(K)")
}
if(minibatch < nrow(X)){
if(max(epsilon) > -Inf){
warning("Stochastic EM algorithm with minibatching ignores epsilon. Set epsilon = -Inf to ignore this message")
epsilon <- rep(-Inf, length(K))
}
warning("Minibatch version of EM does not seem to work at this point. ")
}
out <- list()
cnt <- 1
for(k in K){
if(verbose){
cat("Number of components:", k)
}
N_comp <- k
# Initialize model
SX <- cov(X)
a_n <- function(n, kap=0.75) n^(-kap)
pi <- (tmp <- runif(N_comp))/sum(tmp)
mu <- sigma <- list()
for(j in 1:N_comp){
mu[[j]]    <- X[sample(nrow(X), 1),]
sigma[[j]] <- as.matrix(rWishart(1, df=ncol(X)+2, SX)[,,1])
}
n <- nrow(X)
p <- N_comp
d <- nrow(SX)
pi_ij <- matrix(0, nrow=n, ncol=p)
iter <- 1
tol <- Inf
log_lik <- rep(NA, max_iter)
eps0 <- epsilon[which(K==k)]
while(tol > eps0 & iter < max_iter){
sub_samp <- sample(n, minibatch, replace=FALSE)
#E-STEP
for(i in sub_samp){
for(j in 1:p){
xi <- X[i,]
pi_ij[i,j] <- pi[j] * dmvnorm(as.numeric(xi), as.numeric(mu[[j]]), sigma[[j]])
}
}
for(i in sub_samp){
pi_ij[i,] <- pi_ij[i,]/sum(pi_ij[i,])
}
# M-STEP
Sj <- list()
for(j in 1:p){
tmp <- matrix(0, nrow=d, ncol=d)
for(i in sub_samp){
xi <- X[i,]
tmp <- tmp + pi_ij[i,j]*tcrossprod(xi - mu[[j]])
}
Sj[[j]] <- tmp
}
#Update component probabilities
pi <- apply(pi_ij[sub_samp,,drop=F], 2, mean)
#Update covariance matrices
for(j in 1:p){
sigma[[j]] <- as.matrix((2*a_n(n, kappa)*SX + Sj[[j]])/(2*a_n(n, kappa) + n*pi[j]))
}
#Update mean vectors
for(j in 1:p){
tmp <- 0
for(i in sub_samp){
xi <- X[i,]
tmp <- tmp + pi_ij[i,j]*xi
}
mu[[j]] <- tmp/(minibatch*pi[j])
}
#Compute log likelihood
log_lik[iter] <- log(n) - log(minibatch)
for(i in sub_samp){
tmp <- 0
xi <- X[i,]
for(j in 1:p){
tmp <- tmp + pi[j]*mvtnorm::dmvnorm(xi, mu[[j]], sigma[[j]])
}
log_lik[iter] <- log_lik[iter] + log(tmp)
}
if((iter %% print_iter) == 0){
if(verbose)
cat("\nIteration:", iter, ", tol:", tol, ", log-lik:", log_lik[iter])
}
if(iter > 1){
tol <- log_lik[iter] - log_lik[iter - 1]
}
iter <- iter + 1
}
log_lik <- log_lik[1:(iter - 1)]
out[[cnt]] <- list(k=k,
log_lik = log_lik,
pi = pi,
mu = mu,
sigma = sigma)
cnt <- cnt + 1
if(verbose){
cat("\n\n")
}
}
if(!is.null(crit)){
nvar <- ncol(X)
Kmax <- length(out)
bic <- ll <- rep(NA, Kmax)
aic <- hqic <- rep(NA, Kmax)
kvec <- rep(NA, Kmax)
kk <- 1
for(k in K){
kvec[kk] <- k
if(k == 1){
bic[kk] <- -2*sum(log(dmvnorm(X, apply(X, 2, mean), cov(X)))) +
(k-1 + nvar*k + nvar*(nvar+1)/2*k)*log(nrow(X))
aic[kk] <- -2*sum(log(dmvnorm(X, apply(X, 2, mean), cov(X)))) +
(k-1 + nvar*k + nvar*(nvar+1)/2*k)*2
hqic[kk] <- -2*sum(log(dmvnorm(X, apply(X, 2, mean), cov(X)))) +
(k-1 + nvar*k + nvar*(nvar+1)/2*k)*2*log(log(n))
ll[kk] <- sum(log(dmvnorm(X, apply(X, 2, mean), cov(X))))
}else{
tmp <- out[[kk]]$log_lik
bic[kk] <- -2*max(tmp) + (k-1 + nvar*k + nvar*(nvar+1)/2*k)*log(nrow(X))
aic[kk] <- -2*max(tmp) + (k-1 + nvar*k + nvar*(nvar+1)/2*k)*2
hqic[kk]<- -2*max(tmp) + (k-1 + nvar*k + nvar*(nvar+1)/2*k)*2*log(log(nrow(X)))
ll[kk] <- max(tmp)
}
kk <- kk + 1
}
out2 <- list(fits=out)
out2$k <- kvec
if("aic" %in% crit){
out2$aic <- aic
}
if("bic" %in% crit){
out2$bic <- bic
}
if("hqic" %in% crit){
out2$hqic <- hqic
}
out2$ll <- ll
return(out2)
}
return(out)
}
document()
devtools::document()
devtools::document()
library(quack)
